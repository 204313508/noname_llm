import streamlit as st
from transformers import AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer
import torch
from threading import Thread
import time

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ— åæ€AI v3.0 åœ¨çº¿ç‰ˆ- by AKAè‡­è„¸ç¾Šé©¼",
    page_icon="ğŸ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ¨¡å‹åŠ è½½å‡½æ•°
@st.cache_resource
def load_model():
    try:
        with st.spinner("ğŸ¦™ æ­£åœ¨åŠ è½½æ¨¡å‹ï¼Œé¦–æ¬¡åŠ è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´..."):
            model = AutoModelForCausalLM.from_pretrained(
                "huskyhong/noname-ai-v3.0",
                torch_dtype="auto",
                device_map="auto"
            )
            tokenizer = AutoTokenizer.from_pretrained("./models")
        return model, tokenizer
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
        st.stop()

# åŠ è½½æ¨¡å‹
model, tokenizer = load_model()

# ä¾§è¾¹æ 
with st.sidebar:
    st.title("ğŸ’– æ”¯æŒå¼€å‘è€…")
    try:
        st.image("èµèµç .jpg", 
                caption="æ‚¨çš„æ”¯æŒæ˜¯æˆ‘æ›´æ–°çš„åŠ¨åŠ›", 
                use_container_width=True)
    except FileNotFoundError:
        st.warning("æ‰¾ä¸åˆ°èµèµç å›¾ç‰‡")

# ä¸»ç•Œé¢
st.title("ğŸ® æ— åæ€AI v3.0 -ç½‘é¡µç«¯")

st.markdown("---")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "generating" not in st.session_state:
    st.session_state.update({
        "generating": False,
        "first_token_received": False
    })

# æ¨¡å¼é€‰æ‹©
mode = st.radio("è¯·é€‰æ‹©ç”Ÿæˆæ¨¡å¼ï¼š", ["æŠ€èƒ½ç”Ÿæˆ", "å¡ç‰Œç”Ÿæˆ"], horizontal=True)
prompt_map = {
    "æŠ€èƒ½ç”Ÿæˆ": "è¯·å¸®æˆ‘ç”¨JavaScriptç¼–å†™ä¸€ä¸ªæ— åæ€æ¸¸æˆçš„æŠ€èƒ½ï¼ŒæŠ€èƒ½æ•ˆæœå¦‚ä¸‹ï¼š",
    "å¡ç‰Œç”Ÿæˆ": "è¯·å¸®æˆ‘ç”¨JavaScriptç¼–å†™ä¸€å¼ æ— åæ€æ¸¸æˆçš„å¡ç‰Œï¼Œå¡ç‰Œæ•ˆæœå¦‚ä¸‹ï¼š"
}

# è¾“å…¥åŒºåŸŸ
effect_desc = st.text_area(
    "âœï¸ æ•ˆæœæè¿°ï¼š",
    height=100,
    placeholder="è¯·è¾“å…¥æƒ³è¦å®ç°çš„æŠ€èƒ½/å¡ç‰Œæ•ˆæœæè¿°..."
)

# ç”ŸæˆæŒ‰é’®
if st.button("ğŸš€ å¼€å§‹ç”Ÿæˆ", use_container_width=True):
    if not effect_desc.strip():
        st.warning("âš ï¸ è¯·è¾“å…¥æ•ˆæœæè¿°ï¼")
        st.stop()
    
    # é‡ç½®çŠ¶æ€
    st.session_state.update({
        "generating": True,
        "first_token_received": False
    })
    
    # æ„å»ºæç¤ºè¯
    prompt = prompt_map[mode] + effect_desc.strip()
    
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ç”±Bç«™upä¸»AKAè‡­è„¸è‡­ç¾Šé©¼è®­ç»ƒå¾—åˆ°çš„æ— åæ€AIï¼Œæ—¨åœ¨å¸®åŠ©ç”¨æˆ·ç¼–å†™æ— åæ€æŠ€èƒ½æˆ–å¡ç‰Œä»£ç "},
        {"role": "user", "content": prompt}
    ]
    
    # å‡†å¤‡ç”Ÿæˆå‚æ•°
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
    streamer = TextIteratorStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)

    # çŠ¶æ€åˆå§‹åŒ–
    status_area = st.empty()
    code_output = st.empty()
    full_response = ""
    start_time = time.time()

    # å¯åŠ¨ç”Ÿæˆçº¿ç¨‹
    def generate():
        try:
            model.generate(**model_inputs, streamer=streamer, max_new_tokens=8192)
        except Exception as e:
            st.error(f"âŒ ç”Ÿæˆé”™è¯¯ï¼š{str(e)}")
        finally:
            st.session_state.generating = False

    thread = Thread(target=generate)
    thread.start()

    # å®æ—¶çŠ¶æ€å¤„ç†
    while st.session_state.generating:
        # æ˜¾ç¤ºåˆå§‹ç­‰å¾…æç¤º
        if not st.session_state.first_token_received:
            elapsed_time = time.time() - start_time
            status_message = f"""
            ğŸ•’ æ­£åœ¨åŠªåŠ›ç”Ÿæˆä¸­... ({elapsed_time:.1f}s)
            ![æ­£åœ¨åŠ è½½](https://i.gifer.com/ZZ5H.gif)
            â³ æ¨¡å‹åˆå§‹åŒ–å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
            """
            status_area.markdown(status_message, unsafe_allow_html=True)
        
        # å°è¯•è·å–æµå¼è¾“å‡º
        try:
            for token in streamer:
                # æ”¶åˆ°ç¬¬ä¸€ä¸ªtokenæ—¶æ¸…é™¤ç­‰å¾…æç¤º
                if not st.session_state.first_token_received:
                    status_area.empty()
                    st.session_state.first_token_received = True
                
                full_response += token
                code_output.code(full_response)
                break  # é€ä¸ªtokenå¤„ç†
        except StopIteration:
            break
        
        time.sleep(1)

    # æœ€ç»ˆå¤„ç†
    status_area.empty()
    if full_response:
        st.success("âœ… ç”Ÿæˆå®Œæˆï¼")
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ä»£ç ",
            data=full_response,
            file_name="generated_code.js",
            mime="text/javascript",
            use_container_width=True
        )
    else:
        st.warning("âš ï¸ æœªèƒ½ç”Ÿæˆæœ‰æ•ˆå†…å®¹ï¼Œè¯·å°è¯•è°ƒæ•´è¾“å…¥æè¿°")